# Smart-Cab-with-Qlearning-and-SARSA

The folder, "Smart Cab RL" contains 4 subfolder: "Smart Cab Q-learning", "Smart Cab Q-Learning REWARD=0", "Smart Cab SARSA", "Smart Cab SARSA REWARD=0".
Each of these folder contains the file for running or training the smart cab using Q-learning and SARSA algorithm with different reward function.

To run/train the smart cab:
1) Open command prompt, cmd.
2) Change the directory to whichever smart cab you want to run/train.
3) type: "python RL.py", and hit enter.
4) It will the ask for your input: "Enter 'TRAIN' to train or 'RUN' to run the game:"
5) type 'RUN' or 'TRAIN' and it will do the required task.

## MOTIVATION
â€¢ To study and compare Q Learning and SARSA algorithm. <Br/>
â€¢ Model free and Model based RL algorithm. <Br/>
â€¢ Approach Temporal difference learning learns how to predict a quantity that depends on future values of a
given signal learns from experience. <Br/>
â€¢ Temporal difference update step: <Br/>
  
      ğ‘ğ‘’ğ‘¤ğ¸ğ‘ ğ‘¡ğ‘–ğ‘šğ‘ğ‘¡ğ‘’ â† ğ‘‚ğ‘™ğ‘‘ğ¸ğ‘ ğ‘¡ğ‘–ğ‘šğ‘ğ‘¡ğ‘’ + ğ‘†ğ‘¡ğ‘’ğ‘ğ‘ ğ‘–ğ‘§ğ‘’[ğ‘‡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ âˆ’ ğ‘œğ‘™ğ‘‘ğ¸ğ‘ ğ‘¡ğ‘–ğ‘šğ‘ğ‘¡ğ‘’]

## SMART CAB GAME

â€¢ Inspired from OpenAI gym environment. <Br/>
â€¢ 2D grid 5x5 cells. <Br/>
â€¢ Agent Cab <Br/>
â€¢ Drop off and pick up locations. <Br/>
â€¢ Objective of the game: <Br/>
1. pick up the passenger.
2. drop off the passenger at the right location.
3. take as minimum time as possible. <Br/>

â€¢ Coordinate System: See Screenshot. <Br/>
â€¢ Pickup positions: [0, 0], [0, 4], [4, 0] and [4, 3]. <Br/>
â€¢ Dropoff positions: [0, 0], [0, 4], [4, 0] and [4, 3]. <Br/>
â€¢ Rules: <Br/>
1. Drop off location should not be equal to Pickup location in one episode.
2. Cab cannot go through the walls.
3. Cab can move â€œUPâ€, â€œDOWNâ€, â€œLEFTâ€, and â€œRIGHT. No Diagonal
4. Cannot go beyond the extreme rows and columns.

## Grid
![Grid](https://user-images.githubusercontent.com/31696557/131404076-1858a8a4-fa64-4ab0-9535-1f0af25221b3.png)

## REWARD FUNCTION
```math
ğ‘…ğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘(ğ‘ ,ğ‘)=âˆ’1ğ‘“ğ‘œğ‘Ÿğ‘’ğ‘£ğ‘’ğ‘Ÿğ‘¦ğ‘ ğ‘¡ğ‘’ğ‘âˆ’10ğ‘ğ‘–ğ‘ğ‘˜ğ‘¢ğ‘ğ‘“ğ‘Ÿğ‘œğ‘šğ‘¤ğ‘Ÿğ‘œğ‘›ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›âˆ’10ğ‘‘ğ‘Ÿğ‘œğ‘ğ‘œğ‘“ğ‘“ğ‘ğ‘¡ğ‘¤ğ‘Ÿğ‘œğ‘›ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›+30ğ‘œğ‘Ÿ0ğ‘ğ‘–ğ‘ğ‘˜ğ‘¢ğ‘ğ‘“ğ‘Ÿğ‘œğ‘šğ‘Ÿğ‘–ğ‘”â„ğ‘¡ğ‘™ğ‘œğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›+20ğ‘‘ğ‘Ÿğ‘œğ‘ğ‘œğ‘“ğ‘“ğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘”â„ğ‘¡ğ‘™ğ‘œğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›
```

<img src="https://render.githubusercontent.com/render/math?math=e^{i \pi} = -1">


![formula](https://render.githubusercontent.com/render/math?math=e^{i \pi} = -1)
